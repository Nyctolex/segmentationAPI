{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional\n",
    "from torch import Tensor\n",
    "from PIL.Image import Image as PILImage\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "\n",
    "type ImageType  = str | Tensor | PILImage\n",
    "\n",
    "\n",
    "class ImageToTensor:\n",
    "    foo = lambda x: x\n",
    "    # mappes the type of input to the correct convertion function\n",
    "    type_to_function: dict[type, Callable] = {\n",
    "            #TODO: handle str case\n",
    "            str: foo,\n",
    "            Tensor: lambda x: x,\n",
    "            PILImage: pil_to_tensor\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def convert(cls, image: ImageType) -> Tensor:\n",
    "        if not type(image) in cls.type_to_function:\n",
    "            raise NotImplementedError(f'Type {type(image)} is not supported for prediction')\n",
    "        return cls.type_to_function[type(image)](image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SegmentationModelAI():\n",
    "    def __init__(self, model, preprocessor: Optional[Callable] = None):\n",
    "        #TODO support torch and ONNX\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def predict_batch(self, batch: Tensor) -> Tensor:\n",
    "        return self.model(batch)\n",
    "\n",
    "    def predict_single(self, tensor: Tensor) -> Tensor:\n",
    "        return self.predict_batch(tensor.unsqueeze(0))\n",
    "\n",
    "    def __call__(self, image: ImageType) -> Tensor:\n",
    "        tensor  = ImageToTensor.convert(image)\n",
    "        if self.preprocessor:\n",
    "            tensor = self.preprocessor(tensor)\n",
    "        return self.predict_single(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabV3 as DeepLabV3Type\n",
    "from torch import TensorType\n",
    "type ModelType = rt.capi.onnxruntime_inference_collection.InferenceSession\n",
    "\n",
    "class ModelWrapper():\n",
    "    def __init__(self, model, preprocessor: Optional[Callable] = None):\n",
    "        self.__model = None\n",
    "        self.model = model\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def supported_model_types(self):\n",
    "        \"\"\"Return a tuple of supported model types for the subclass.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self.__model\n",
    "    \n",
    "    @model.setter\n",
    "    def model(self, new_model):\n",
    "        print(new_model, type(new_model))\n",
    "        if not self.validate_model_type(new_model):\n",
    "            raise TypeError(f\"Unsupported model type. Supported types are: {self.supported_model_types}\")\n",
    "        self.__model = new_model\n",
    "\n",
    "\n",
    "    def validate_model_type(self, new_model) -> bool:\n",
    "        return isinstance(new_model, self.supported_model_types)\n",
    "    \n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict_single(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict_batch(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        raise NotImplemented\n",
    "    \n",
    "\n",
    "class DeepLabV3Wrapper(ModelWrapper):\n",
    "    \n",
    "    @property\n",
    "    def supported_model_types(self):\n",
    "        return (DeepLabV3Type,)\n",
    "\n",
    "    def predict_batch(self, batch_images: TensorType) -> TensorType:\n",
    "        \"\"\"Predicts the output of the model for a batch of images.\n",
    "\n",
    "        Args:\n",
    "            batch_images (TensorType): A tensor of shape [N, 3, H, W]\n",
    "\n",
    "        Returns:\n",
    "            TensorType: The model prediction \n",
    "        \"\"\"\n",
    "        assert len(batch_images.shape) == 4, 'Missmatching tensor dimensions. The image should be of shape [N, 3, H, W]'\n",
    "        assert batch_images.shape[1] == 3, f'Missmatching tensor dimensions. The image should have 3 collor images but found {batch_images.shape[1]}'\n",
    "        if self.preprocessor:\n",
    "            batch_images = self.preprocessor(batch_images)\n",
    "        return self.model(batch_images)\n",
    "    \n",
    "    def predict_single(self, image: Tensor) -> TensorType:\n",
    "        \"\"\"Predicts the output of the model for a single image.\n",
    "\n",
    "        Args:\n",
    "            image (Tensor): The image tensor of shape [3, H, W]\n",
    "\n",
    "        Returns:\n",
    "            TensorType: The model prediction (logits)\n",
    "            TODO: change from logit to classes\n",
    "        \"\"\"\n",
    "        assert len(image.shape) == 3, 'Missmatching tensor dimensions. The image should be of shape [3, H, W]'\n",
    "        assert image.shape[0] == 3, f'Missmatching tensor dimensions. The image should have 3 collor images but found {image.shape[1]}'\n",
    "        return self.predict_batch(image.unsqueeze(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <class 'int'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unsupported model type. Supported types are: (<class 'str'>,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m w1 \u001b[38;5;241m=\u001b[39m \u001b[43mDeepLabV3Wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# w1.model = 1\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[45], line 7\u001b[0m, in \u001b[0;36mModelWrapper.__init__\u001b[0;34m(self, model, preprocessor)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, preprocessor: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessor \u001b[38;5;241m=\u001b[39m preprocessor\n",
      "Cell \u001b[0;32mIn[45], line 24\u001b[0m, in \u001b[0;36mModelWrapper.model\u001b[0;34m(self, new_model)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_model, \u001b[38;5;28mtype\u001b[39m(new_model))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_model_type(new_model):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported model type. Supported types are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupported_model_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__model \u001b[38;5;241m=\u001b[39m new_model\n",
      "\u001b[0;31mTypeError\u001b[0m: Unsupported model type. Supported types are: (<class 'str'>,)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Test\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large, DeepLabV3_MobileNet_V3_Large_Weights\n",
    "# Step 1: Initialize model with the best available weights\n",
    "weights = DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT\n",
    "model = deeplabv3_mobilenet_v3_large(weights=weights)\n",
    "model.eval()\n",
    "preprocess = weights.transforms()\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/deeplab1.png\", \"deeplab1.png\")\n",
    "input_image = Image.open(filename)\n",
    "input_image = input_image.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Type <class 'list'> is not supported for prediction",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m seg \u001b[38;5;241m=\u001b[39m SegmentationModelAI(model, preprocess)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mseg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 39\u001b[0m, in \u001b[0;36mSegmentationModelAI.__call__\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: ImageType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 39\u001b[0m     tensor  \u001b[38;5;241m=\u001b[39m \u001b[43mImageToTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessor:\n\u001b[1;32m     41\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessor(tensor)\n",
      "Cell \u001b[0;32mIn[38], line 22\u001b[0m, in \u001b[0;36mImageToTensor.convert\u001b[0;34m(cls, image)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\u001b[38;5;28mcls\u001b[39m, image: ImageType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(image) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mtype_to_function:\n\u001b[0;32m---> 22\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(image)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported for prediction\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mtype_to_function[\u001b[38;5;28mtype\u001b[39m(image)](image)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Type <class 'list'> is not supported for prediction"
     ]
    }
   ],
   "source": [
    "seg = SegmentationModelAI(model, preprocess)\n",
    "seg([1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Course: DSA'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Geeks:\n",
    "    course = 'DSA'\n",
    "    list_of_instances = []\n",
    "\n",
    "    def _init_(self, name):\n",
    "        self.name = name\n",
    "        Geeks.list_of_instances.append(self)\n",
    "\n",
    "    @classmethod\n",
    "    def get_course(cls):\n",
    "        return f\"Course: {cls.course}\"\n",
    "Geeks.get_course()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
